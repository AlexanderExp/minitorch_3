# Разбор `_tensor_matrix_multiply`

Мы хотим посчитать умножение матриц:

```
out[n, i, j] = Σ_k  a[n, i, k] * b[n, k, j]
```

Формы:

* `a`: `(N_a или 1, I, K)`
* `b`: `(N_b или 1, K, J)`
* `out`: `(N = broadcast(N_a, N_b), I, J)`

Если у `a` или `b` размер равен 1, он растягивается (broadcast).

---

# Что делает каждая строка

```python
a_batch_stride = int(a_strides[0]) if int(a_shape[0]) > 1 else 0
b_batch_stride = int(b_strides[0]) if int(b_shape[0]) > 1 else 0
```

* Если батч у тензора реально >1, нужно сдвигаться по памяти при смене `n` на `a_strides[0]` / `b_strides[0]`.
* Если батч = 1 (broadcast), шаг 0: всегда читаем один и тот же батч-срез.

```python
N = int(out_shape[0]); I = int(out_shape[1]); J = int(out_shape[2])
K = int(a_shape[2])
```

* Размеры по батчу/строкам/столбцам и общая размерность `K` (совместная ось).

```python
os0, os1, os2 = int(out_strides[0]), int(out_strides[1]), int(out_strides[2])
as1, as2 = int(a_strides[1]),  int(a_strides[2])   # (ось I, ось K)
bs1, bs2 = int(b_strides[1]),  int(b_strides[2])   # (ось K, ось J)
```

* Берём страйды (шаги в элементах) как `int`, чтобы индексация была целочисленной.
* В `a` нас интересуют шаги по `I` и `K`.
* В `b` — шаги по `K` и `J`.

```python
total = N * I * J
for ord_ in prange(total):
```

* Внешний цикл идёт по всем элементам out и распараллеливается (`prange`).
* Каждая итерация пишет в уникальный адрес результата.

```python
n = ord_ // (I * J)
rem = ord_ - n * (I * J)
i = rem // J
j = rem - i * J
```

* Превращаем скалярный номер итерации `ord_` в тройку индексов `(n,i,j)` (развёртка без буферов и вызовов).

```python
out_pos = n * os0 + i * os1 + j * os2
```

* **Линейный адрес** для записи в `out` по формуле `Σ index[d] * strides[d]`.

```python
a_base = n * a_batch_stride + i * as1        # k=0 → + 0 * as2
b_base = n * b_batch_stride + j * bs2        # k=0 → + 0 * bs1
```

* Базовые адреса «начала строки/столбца»:

  * для `a` фиксируем `(n,i, k=0)` → старт `a_base`, далее шаг по `K` = `as2`;
  * для `b` фиксируем `(n, k=0, j)` → старт `b_base`, далее шаг по `K` = `bs1`.

```python
acc = 0.0
a_pos = a_base
b_pos = b_base
for _k in range(K):
    acc += float(a_storage[a_pos]) * float(b_storage[b_pos])
    a_pos += as2          # двигаемся по k в 'a'
    b_pos += bs1          # и по k в 'b'
out[out_pos] = acc
```

* Внутренний цикл — только локальные переменные, одна операция «умножение+сложение» в шаге.

# Примеры

## 1) Обычное 2D умножение (через батч=1)

Пусть:

```
A (I=2,K=3) = [[1,2,3],
               [4,5,6]]
B (K=3,J=2) = [[ 7,  8],
               [ 9, 10],
               [11, 12]]
```

Обёртка делает из них 3D: `A→(1,2,3)`, `B→(1,3,2)`. Cтрайды будут:

```
out shape (1,2,2), out_strides = (4, 2, 1)   # (N,I,J) → (I*J, J, 1)
A   shape (1,2,3), A_strides   = (6, 3, 1)   # (N,I,K) → (I*K, K, 1)
B   shape (1,3,2), B_strides   = (6, 2, 1)   # (N,K,J) → (K*J, J, 1)
```

Возьмём элемент `out[0, 1, 0]` (`n=0,i=1,j=0`):

```
out_pos = 0*4 + 1*2 + 0*1 = 2
a_base  = 0*6 + 1*3       = 3   → A по k: pos = 3,4,5  → значения 4,5,6
b_base  = 0*6 + 0*1       = 0   → B по k: pos = 0,2,4  → значения 7,9,11
acc = 4*7 + 5*9 + 6*11 = 28 + 45 + 66 = 139
out[2] = 139
```

И это ровно ожидаемый результат для 2D матмул.

## 2) Без бродкаста

`A: (2, I=2, K=2)`, `B: (2, K=2, J=2)` — у каждого батча своя матрица.
Для 3D страйдов:

```
A_strides = (I*K, K, 1) = (4, 2, 1)
B_strides = (K*J, J, 1) = (4, 2, 1)
```

Тогда `a_batch_stride = 4`, `b_batch_stride = 4`.
При переходе `n=0 → n=1` `a_base` и `b_base` смещаются на +4 элементов — читаются другие срезы.

## 3) broadcast
разберём **пошаговый пример матмул с broadcasting по батчу** в двух вариантах:

1. вещь `A` одна для всех батчей (broadcast `A`), `B` — разный по батчу;
2. наоборот: `B` одна для всех батчей (broadcast `B`), `A` — разный по батчу.

Во всех примерах — плотные C-континуальные тензоры, поэтому страйды стандартные:

* для формы `(N, I, J)` страйды: `(I*J, J, 1)`.

---

# Вариант 1 — Broadcast `A`: `A` имеет батч=1, `B` — батч=2

**Формы**

* `A`: `(1, I=2, K=3)`

  ```
  A[0] = [[1, 2, 3],
          [4, 5, 6]]
  ```
* `B`: `(2, K=3, J=2)`

  ```
  B[0] = [[10, 11],
          [12, 13],
          [14, 15]]

  B[1] = [[ 7,  8],
          [ 9, 10],
          [11, 12]]
  ```
* `out`: `(N=2, I=2, J=2)`

**Страйды (C-order)**

* `out_strides = (I*J, J, 1) = (4, 2, 1)`
* `a_strides   = (I*K, K, 1) = (6, 3, 1)`
* `b_strides   = (K*J, J, 1) = (6, 2, 1)`

**Batch strides в коде**

```python
a_batch_stride = 0                # a_shape[0] == 1 → broadcast
b_batch_stride = 6                # b_shape[0] == 2 → реальный батч
```

**Что делает ядро**

Внешний цикл идёт по всем `ord_` от `0` до `N*I*J - 1 = 7`.
Каждому `ord_` соответствует тройка `(n, i, j)`:

```
n = ord_ // (I*J)
rem = ord_ - n*(I*J)
i = rem // J
j = rem - i*J
```

Адреса:

```
out_pos = n*os0 + i*os1 + j*os2
a_base  = n*a_batch_stride + i*as1      # т.к. a_batch_stride=0, не зависит от n
b_base  = n*b_batch_stride + j*bs2
a_pos(k)= a_base + k*as2
b_pos(k)= b_base + k*bs1
```

Давайте посчитаем **все** элементы `out` (результаты сверху для сверки):

* `out[0,0,0] = [1,2,3]·[10,12,14] = 76`
* `out[0,0,1] = [1,2,3]·[11,13,15] = 82`
* `out[0,1,0] = [4,5,6]·[10,12,14] = 184`
* `out[0,1,1] = [4,5,6]·[11,13,15] = 199`
* `out[1,0,0] = [1,2,3]·[ 7, 9,11] = 58`
* `out[1,0,1] = [1,2,3]·[ 8,10,12] = 64`
* `out[1,1,0] = [4,5,6]·[ 7, 9,11] = 139`
* `out[1,1,1] = [4,5,6]·[ 8,10,12] = 154`

Разберём **одну** итерацию детально, например `ord_ = 6` → `(n,i,j) = (1,1,0)`:

* Распаковка:

  ```
  n = 6 // 4 = 1
  rem = 6 - 1*4 = 2
  i = 2 // 2 = 1
  j = 2 - 1*2 = 0
  ```
* Адрес записи:

  ```
  out_pos = 1*4 + 1*2 + 0*1 = 6
  ```
* Базы:

  ```
  a_base = n*0 + i*3 = 3         # читаем A[0,1,:] → pos 3,4,5 → 4,5,6
  b_base = n*6 + j*1 = 6         # читаем B[1,:,0] → pos 6,8,10 → 7,9,11
  ```
* Аккумуляция:

  ```
  acc = 4*7 + 5*9 + 6*11 = 28 + 45 + 66 = 139
  out[6] = 139
  ```

Видно, что `A` действительно «заброадкастился» по батчу: `a_base` **не зависит** от `n` (потому что `a_batch_stride=0`). А у `B` при смене `n` база сдвигается на `+6`.

---

# Вариант 2 — Broadcast `B`: `B` имеет батч=1, `A` — батч=2

Поменяем местами: теперь у нас **одна** матрица `B` (общая для всех батчей), а `A` разная по `n`.

**Формы**

* `A`: `(2, I=2, K=3)`

  ```
  A[0] = [[1, 2, 3],
          [4, 5, 6]]

  A[1] = [[ 2,  1,  0],
          [ 3, -1,  2]]
  ```
* `B`: `(1, K=3, J=2)`

  ```
  B[0] = [[10, 11],
          [12, 13],
          [14, 15]]
  ```
* `out`: `(2, 2, 2)`

**Страйды**

* `out_strides = (4, 2, 1)`
* `a_strides   = (6, 3, 1)`  → `a_batch_stride = 6` (реальный батч)
* `b_strides   = (6, 2, 1)`  → `b_batch_stride = 0` (broadcast по батчу)

Возьмём, например, элемент `out[1, 0, 1]`:

* Индекс: `(n,i,j)=(1,0,1)` → `out_pos = 1*4 + 0*2 + 1 = 5`.
* Базы:

  ```
  a_base = n*a_batch_stride + i*as1 = 1*6 + 0*3 = 6
          → читаем A[1,0,:] по k: pos 6,7,8 → [2,1,0]

  b_base = n*0 + j*bs2 = 0 + 1*1 = 1
          → читаем B[0,:,1] по k: pos 1,3,5 → [11,13,15]
  ```
* Аккумуляция:

  ```
  acc = 2*11 + 1*13 + 0*15 = 35
  out[5] = 35
  ```

Здесь видно, что теперь `B` не «двигается» по батчу (`b_batch_stride=0`), а `A` — меняется (`a_batch_stride=6`).

---

# Что важно заметить

* В обоих вариантах broadcasting по батчу реализуется чисто страйдами:

  * если размер по батчу = 1 → соответствующий «batch stride» = 0;
    мы всегда читаем один и тот же срез.
  * если размер по батчу > 1 → stride нормальный;
    при смене `n` мы сдвигаемся на `a_strides[0]`/`b_strides[0]`.
* Адреса внутри внутреннего цикла по `k` идут простым линейным шагом:

  ```
  a_pos += as2   # ось K в A
  b_pos += bs1   # ось K в B
  ```

  Это одинаково работает и для обычных, и для «перемешанных»/срезанных тензоров, потому что страйды всегда «правильные» для конкретного размещения.




# Производительность

* **Внешний цикл** — `prange`: распараллеливание по всем `(n,i,j)`.
* **Нет буферов индексов и вызовов** в горячих местах: разворачивание `(n,i,j)` из `ord_` и линейные формулы адресов.
* **Внутренний цикл** по `k` — только локальные переменные и 1 умножение + 1 сложение за шаг. Глобальная запись ровно одна — в конце итерации.

Сложность по времени: `O(N * I * J * K)`.
Память дополнительная: O(1).

---

# Короткая «шпаргалка» по формулам

* Распаковка номера итерации:

  ```
  n = ord_ // (I*J)
  rem = ord_ - n*(I*J)
  i = rem // J
  j = rem - i*J
  ```
* Линейные адреса:

  ```
  out_pos = n*os0 + i*os1 + j*os2
  a_base  = n*a_batch_stride + i*as1     # k = 0
  b_base  = n*b_batch_stride + j*bs2     # k = 0
  a_pos = a_base + k*as2
  b_pos = b_base + k*bs1
  ```
* Аккумуляция:

  ```
  acc = Σ_{k=0..K-1}  a[a_pos(k)] * b[b_pos(k)]
  out[out_pos] = acc
  ```